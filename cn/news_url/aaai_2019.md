# 实验室多篇论文被AAAI 2019接收

在即将到来的第三十三届AAAI人工智能会议（AAAI-19）上，实验室**五篇论文**被接收。AAAI-19共收到超过**7700**份论文投稿，其中**1150**篇论文被录用，接受率仅为**16.2%**。实验室被录用论文主要集中在立体视觉内容表示和基于超图结构的神经网络模型两个方面。

被录用的论文如下：
**MeshNet: Mesh Neural Network for 3D Shape Representation**

**摘要**：网格（mesh）作为三维物体的一类重要且有效的数据类型，在计算机视觉和计算机图形学领域得到了广泛的研究。在表示三维物体的任务中，近年来已经有许多基于体素、多视图和点云的三维物体表示方法研究，而基于网格数据的研究却非常缺乏，这主要是由网格自身的复杂性和不规则性造成的。在本篇文章中，我们提出了一种名为 MeshNet 的网格神经网络，它能够直接基于网格数据进行三维物体表示。在该方法中，我们提出了以面为单元和分割面特征的方法，并提出了一个包含多个新型模块的通用网络结构。通过我们的方法，MeshNet 能够解决网格数据的复杂性和不规则形问题，从而进行良好的三维物体表示。我们把该方法应用到了三维物体的分类和检索任务中，实验结果及同其他当前最优方法的对比表明，MeshNet 能够达到令人满意的分类和识别效果，从而表明了其在表示三维物体方面的有效性。

<div align="center"{margin:10%}><img src=http://gaoyue.org/news_img/20181101_1.png width=80% height=80%>
</div>




**MLVCNN: Multi-Loop-View Convolutional Neural Network for 3D Shape Retrieval** 

**Abstract:** 三维对象检索近年来受到了人们的广泛关注, 成为计算机视觉领域的一个热门话题。随着深度学习的发展, 三维对象检索也取得了很大的进步, 近年来引入了许多基于视图的方法。然而, 如何更好地表示三维对象仍然是一个具有挑战性的问题。同时, 在现有方法中视图之间的内在层次结构关联仍未得到很好的利用。为了解决这些问题, 本文提出了一种用于三维对象检索的多环路视图卷积神经网络 (MLVCNN) 框架。在此方法中, 首先从不同的环路方向提取多组视图。考虑到更好的利用这些环路特性, 提出的 MLVCNN 框架引入了分层次的视图-环路-对象框架结构。在视图级别中, 首先训练卷积神经网络来提取视图特征。然后, 将提出的环路归一化模块和长短时神经网络用于每个视图环路以生成环路级特征。最后, 将所有的环路描述子拼接到一个对象级描述子中, 用于三维对象表示。我们提出的方法已在公开的三维对象基准数据集 (modelnet40) 上进行了评估。同当前最优的方法的比较的实验表明, 所提出的 MLVCNN 方法可以显著提高三维形状检索任务的性能。我们还评估了所提出的方法在三维对象分类任务上的性能, MLVCNN 与最近的方法相比, 也取得了优异的性能。 

<div align="center"{margin:10%}><img src=http://gaoyue.org/news_img/20181101_2.png width=80% height=80%>
</div>



**DeepCCFV: Camera Constraint-Free Multi-View Convolutional Neural Network for 3D Object Retrieval**

**Abstract**：以MVCNN为代表的众多基于多视图3D对象识别和检索方法都取得了令人瞩目的性能表现，但是按照MVCNN的设定，他们要求固定的视图采集位置，这会带来了严重的过拟合问题，本文发现了这里的过拟合问题，并提出有效的方法解决它。

<div align="center"{margin:10%}><img src=http://gaoyue.org/news_img/20181101_3.png width=80% height=80%>
</div>


 



 

**Hypergraph Neural Networks**

**Abstract:** 在本文中我们针对复杂数据的表示学习提出了超图神经网络（HGNN）的框架，这种架构可以在超图结构中编码高维数据关联。在现实中如何学习复杂数据的表示是一个很大的难题。超图结构相比结构化数据表示和传统图结构能更灵活的建模数据关联，特别是复杂的数据关联。为了在超图学习中解决数据复杂关联的问题，我们设计了超边卷积操作。相比传统的超图学习方法，超边卷积的运算更高效。超图神经网络是一个更普适的框架，能够在高维数据结构中学习到数据隐藏层的表示。我们在引用网络节点分类和可视物体识别两个任务中分别对比了图卷积网络和其他的传统方法。实验结果证明了我们提出的方法比现有最好的方法有更优秀的性能。我们同样在处理多模态的数据任务上做了实验，结果表明HGNN在面对复杂数据关联特别是多模态数据的时候有着非常显著的优势。



<div align="center"{margin:10%}><img src=http://gaoyue.org/news_img/20181101_4.png width=80% height=80%>
</div>


 

**PVRNet: Point-View Relation Neural Network for 3D Shape Recognition**

**Abstract:**在计算机视觉领域，三维物体识别被广泛研究。随着深度学习的进步，很多高性能的深度网络模型被提出用来抽取三维特征。对于两种普遍的三维立体表征-点云和多视图数据，很多不同的模型都取得了较好的性能。然而还没去方法取探究这两种数据的相对关系。在本篇文章中，我们介绍了点云视图关系网络(PVRNet)，一种根据点云和视图的关系去融合两种数据的网络。具体来讲，基于关系分数模型，首先我们通过探究点云和单个视图之间的关系来融合点云-单视图特征，然后我们根据点云和多个不同视图的关系来融合点云-多视图特征。最后，点云-单视图特征和点云-多视图特征融合在一起获得三维物体的统一表征。我们提出的点云视图关系网络在ModelNet40数据库上进行验证。实验证明我们模型在三维物体识别和检索上面可以获得超越当前最好的模型的性能。

<div align="center"{margin:10%}><img src=http://gaoyue.org/news_img/20181101_5.png width=50% height=80%>
</div>


